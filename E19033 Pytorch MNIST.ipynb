{"cells":[{"metadata":{"_uuid":"8f02da80b362a4233b75cb0f9e9656525e37befa"},"cell_type":"markdown","source":"![](images/mlp.PNG)"},{"metadata":{"_uuid":"6145a827010b47e713d5bcdb6f89d8042040d75f"},"cell_type":"markdown","source":"# **1. Deep Learning basics with Pytorch**\n"},{"metadata":{"_uuid":"98bee7eaf09d225730006f2b24ca5662d28cfb65"},"cell_type":"markdown","source":"# Kaggle- Multilayered Perceptron (MLP) implemention on MNIST dataset\nLet us now load the dataset from Kaggle repo and train our model"},{"metadata":{"_uuid":"4e83a9e422c10eb07cbfb779be01803d2b8a5334","trusted":true},"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport torch\nfrom torch.utils.data import TensorDataset ,DataLoader\nfrom torch import nn,optim\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nPATH=Path(\"../input\")\nprint(os.listdir(\"../input\"))","execution_count":26,"outputs":[{"output_type":"stream","text":"['train.csv', 'test.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"_uuid":"661e23266c2c882d34cdae4c9074d26c0d2ac040"},"cell_type":"markdown","source":"## Load Data "},{"metadata":{"_uuid":"72b61aac15c29fc295d77130b07d1110c9cb1825","trusted":true},"cell_type":"code","source":"train=pd.read_csv(PATH/'train.csv')\ntest=pd.read_csv(PATH/'test.csv')\ntrain.shape,test.shape","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"((42000, 785), (28000, 784))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vizuvalizing the data set\n\nimport matplotlib.pyplot as plt\nimport numpy\ndef imshow(image, ax=None, title=None, normalize=True):\n\n    if ax is None:\n        fig, ax = plt.subplots()\n        \n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax\n\nplt.imshow(numpy.array(train.iloc[10,1:]).reshape(28,28))\nprint(train.iloc[10,0])\n","execution_count":30,"outputs":[{"output_type":"stream","text":"8\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"_uuid":"6d5eb02dbfc5e385ffd113560494e0b2275e5f66"},"cell_type":"markdown","source":"## Extracting Input and Target Variable"},{"metadata":{"_uuid":"858a074c0e1dea92562d0f1bd93ff5302f861643","trusted":true},"cell_type":"code","source":"x=train.drop(\"label\",axis=1)\ny=np.array(train['label'])\nx.shape,y.shape","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"((42000, 784), (42000,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.from_numpy(x.values[1]).shape","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"torch.Size([784])"},"metadata":{}}]},{"metadata":{"_uuid":"454f4fb8e0a416e60aed471a49850c01a64a77e6"},"cell_type":"markdown","source":"## Train -Test Split -Pytorch"},{"metadata":{"_uuid":"d616496f4e453322efe8aecfa71b17fcdddaa8dd","trusted":true},"cell_type":"code","source":"torch_X_train = torch.from_numpy(x.values).type(torch.FloatTensor)/255\ntorch_y_train = torch.from_numpy(y).type(torch.LongTensor)\nmyDataset = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\nvalid_no  = int(0.2 * len(myDataset))\n\n# so divide the data into trainset (80 %) and testset (20 %)\ntrainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\nprint(f\"len of trainSet {len(trainSet)} , len of testSet {len(testSet)}\")\nbatch_size=80\ntrain_loader  = DataLoader(trainSet , batch_size=batch_size ,shuffle=True) \ntest_loader  = DataLoader(testSet , batch_size=batch_size ,shuffle=True)\n\nprint(f\"len of train_loader {len(train_loader)} , len of test_loader {len(test_loader)}\")\n","execution_count":48,"outputs":[{"output_type":"stream","text":"len of trainSet 33600 , len of testSet 8400\nlen of train_loader 420 , len of test_loader 105\n","name":"stdout"}]},{"metadata":{"_uuid":"97b2925a24f59b10a16864a76f00e02a4c92b36f"},"cell_type":"markdown","source":"## Network"},{"metadata":{"_uuid":"8cbe1c508bacadbb875014318a35fed17ab6a3a1","trusted":true},"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(784, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 64)\n        self.fc4 = nn.Linear(64, 10)\n\n        # Dropout module with 0.2 drop probability\n        self.dropout = nn.Dropout(p=0.1)\n\n    def forward(self, x):\n        # make sure input tensor is flattened\n        x = x.view(x.shape[0], -1)\n\n        # Now with dropout\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n\n        # output so no dropout here\n        x = F.log_softmax(self.fc4(x), dim=1)\n\n        return x\n        \nmodel=Network()\n#optimizer=optim.Adam(model.parameters(),lr=0.01)\n#optimizer=optim.SGD(model.parameters(), lr=0.04, weight_decay= 1e-7, momentum = 0.9,nesterov = True)\noptimizer=torch.optim.Adamax(model.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n#optimizer=torch.optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n\n\ncriterion=nn.CrossEntropyLoss()","execution_count":79,"outputs":[]},{"metadata":{"_uuid":"2bea512cd5bd9f4f41bd77044f471e644505a5fa"},"cell_type":"markdown","source":"## Train "},{"metadata":{"_uuid":"2df4882ed86f9b17b4bba52d56adfde46d1f718d","trusted":true},"cell_type":"code","source":"epochs=15\ntrain_losses,test_losses=[],[]\nfor e in range(epochs):\n    running_loss=0\n    for images,labels in train_loader:\n        optimizer.zero_grad()\n        log_ps=model(images)\n        loss=criterion(log_ps,labels)\n        loss.backward()\n        optimizer.step()\n        running_loss+=loss.item()\n        \n    else:\n        test_loss=0\n        accuracy=0\n        \n        with torch.no_grad():\n            model.eval()\n            for images,labels in test_loader:\n                log_ps=model(images)\n                test_loss+=criterion(log_ps,labels)\n                ps=torch.exp(log_ps)\n                top_p,top_class=ps.topk(1,dim=1)\n                equals=top_class==labels.view(*top_class.shape)\n                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n        model.train()\n        train_losses.append(running_loss/len(train_loader))\n        test_losses.append(test_loss/len(test_loader))\n\n        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))    ","execution_count":81,"outputs":[{"output_type":"stream","text":"Epoch: 1/15..  Training Loss: 0.040..  Test Loss: 0.085..  Test Accuracy: 0.975\nEpoch: 2/15..  Training Loss: 0.036..  Test Loss: 0.086..  Test Accuracy: 0.974\nEpoch: 3/15..  Training Loss: 0.030..  Test Loss: 0.086..  Test Accuracy: 0.975\nEpoch: 4/15..  Training Loss: 0.027..  Test Loss: 0.088..  Test Accuracy: 0.976\nEpoch: 5/15..  Training Loss: 0.023..  Test Loss: 0.086..  Test Accuracy: 0.978\nEpoch: 6/15..  Training Loss: 0.022..  Test Loss: 0.085..  Test Accuracy: 0.978\nEpoch: 7/15..  Training Loss: 0.018..  Test Loss: 0.085..  Test Accuracy: 0.978\nEpoch: 8/15..  Training Loss: 0.018..  Test Loss: 0.084..  Test Accuracy: 0.979\nEpoch: 9/15..  Training Loss: 0.016..  Test Loss: 0.089..  Test Accuracy: 0.976\nEpoch: 10/15..  Training Loss: 0.014..  Test Loss: 0.087..  Test Accuracy: 0.979\nEpoch: 11/15..  Training Loss: 0.012..  Test Loss: 0.093..  Test Accuracy: 0.979\nEpoch: 12/15..  Training Loss: 0.012..  Test Loss: 0.089..  Test Accuracy: 0.978\nEpoch: 13/15..  Training Loss: 0.011..  Test Loss: 0.093..  Test Accuracy: 0.978\nEpoch: 14/15..  Training Loss: 0.010..  Test Loss: 0.091..  Test Accuracy: 0.979\nEpoch: 15/15..  Training Loss: 0.009..  Test Loss: 0.091..  Test Accuracy: 0.979\n","name":"stdout"}]},{"metadata":{"_uuid":"9373aea13cc5891684fb8b801cbcd0ac17eff458"},"cell_type":"markdown","source":"## Save our model"},{"metadata":{"_uuid":"bfcc3f17cadca0bf48cec130586b907965905ed6","trusted":true},"cell_type":"code","source":"print(\"Our model: \\n\\n\", model, '\\n')\nprint(\"The state dict keys: \\n\\n\", model.state_dict().keys())","execution_count":58,"outputs":[{"output_type":"stream","text":"Our model: \n\n Network(\n  (fc1): Linear(in_features=784, out_features=256, bias=True)\n  (fc2): Linear(in_features=256, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=64, bias=True)\n  (fc4): Linear(in_features=64, out_features=10, bias=True)\n  (dropout): Dropout(p=0.2)\n) \n\nThe state dict keys: \n\n odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n","name":"stdout"}]},{"metadata":{"_uuid":"f83335753469344d38ac362053a74fad30b0ca3e","trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), 'checkpoint.pth')","execution_count":60,"outputs":[]},{"metadata":{"_uuid":"70b1a508fd748a8823a9e1af57538e4cacb0621d"},"cell_type":"markdown","source":"## Load our model"},{"metadata":{"_uuid":"abd854b1c8bfed532cb4e64578c40fd29dea9a36","trusted":true},"cell_type":"code","source":"state_dict = torch.load('checkpoint.pth')\nprint(state_dict.keys())","execution_count":61,"outputs":[{"output_type":"stream","text":"odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n","name":"stdout"}]},{"metadata":{"_uuid":"7a889737952161eb1834f521476f0f1c8448570a","trusted":true},"cell_type":"code","source":"model.load_state_dict(state_dict)","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"IncompatibleKeys(missing_keys=[], unexpected_keys=[])"},"metadata":{}}]},{"metadata":{"_uuid":"a08eff1adeb3a8f8f7a31356828ee732a557c3d5","trusted":true},"cell_type":"code","source":"checkpoint = {'input_size': 784,\n              'output_size': 10,\n              'hidden_layers': [256,128,64],\n              'state_dict': model.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint.pth')","execution_count":63,"outputs":[]},{"metadata":{"_uuid":"b3356c9580d6c01685a52a11f906ee1c9dbe7ef1"},"cell_type":"markdown","source":"## Load Test Data"},{"metadata":{"_uuid":"34abb15aa48ad4f133ee15a2f9a5268b45692c36","trusted":true},"cell_type":"code","source":"test_images = pd.read_csv(\"../input/test.csv\")\ntest_image = test_images.loc[:,test_images.columns != \"label\"].values\ntest_dataset = torch.from_numpy(test_image).type(torch.FloatTensor)/255\nprint(test_dataset.shape)\n#test_dataset = torch.utils.data.TensorDataset(test_dataset)\nnew_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)","execution_count":64,"outputs":[{"output_type":"stream","text":"torch.Size([28000, 784])\n","name":"stdout"}]},{"metadata":{"_uuid":"790dd7f94c59a6de5441827b999b6cff6f686154","trusted":true},"cell_type":"code","source":"results = []\nwith torch.no_grad():\n    model.eval()\n    for images in new_test_loader:\n        output = model(images)\n        ps = torch.exp(output)\n        top_p, top_class = ps.topk(1, dim = 1)\n        results += top_class.numpy().tolist()","execution_count":65,"outputs":[]},{"metadata":{"_uuid":"0f9b334b1c25c4bb1a48fda6b64634f1f90b7565"},"cell_type":"markdown","source":"## Check the results"},{"metadata":{"_uuid":"56ffd3051274596232af3ca4d1a9ee7d6322881a","trusted":true},"cell_type":"code","source":"predictions = np.array(results).flatten()\nprint(predictions[:5])\nprint(predictions.shape)","execution_count":66,"outputs":[{"output_type":"stream","text":"[2 0 9 9 3]\n(28000,)\n","name":"stdout"}]},{"metadata":{"_uuid":"f946013a3eab6274d1becd93dfe99aa9f7491cf9"},"cell_type":"markdown","source":"## Submit for Scoring"},{"metadata":{"_uuid":"655160a6e2d490651c0fe70b8ba7480ed8ba1fcc","trusted":true},"cell_type":"code","source":"submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"my_submissions.csv\", index=False, header=True)","execution_count":67,"outputs":[]},{"metadata":{"_uuid":"177c548a264bbaaa76e216eeaf1d747db88b1030"},"cell_type":"markdown","source":"# Reference \n\n[Introduction to Pytorch-Udacity](https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"320px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}